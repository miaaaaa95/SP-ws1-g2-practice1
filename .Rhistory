unique(uni_capital_words)
str(uni_capital_words)
splitted_words_origin[1:100]
unique(tolower(splitted_words_origin[5e5:6e5][unlist(gregexpr("^[A-Z]", splitted_words_origin[5e5:6e5], perl = T)) == 1]))
prob_capital[grep("god", uni_capital_words)]
prob_capital[grep("god", uni_capital_words)]
a <- scan("1581-0.txt", what = "character", skip = 156)
n <- length(a)
a <- a[- ((n - 2909):n)] ## strip license
split_punct <- function(test){
punc <- c(",", ".", ";", "!", ":","?")
for (i in 1:length(punc)) {
p <- punc[i]
ipunc <- grep(p, test, fixed = T) ## search for words containing this mark
npunc <- length(ipunc) ## number of words containing this punctuation
if (npunc == 0) next ## if all words don't contain this punctuation, skip to next loop
spunc <- rep("", length(test) + npunc) ## create a new vectore to store the splited words
sii <- ipunc + 1:npunc ## vector to store the position of this punctuations
spunc[sii] <- p ## insert the punctuations
spunc[sii-1] <- gsub(p, "", test[ipunc], fixed = TRUE) ## insert words the punctuations attacthed to
spunc[-c(sii, sii-1)] <- test[-ipunc] ## insert other words
test <- spunc ## update words vector
}
splitted <- test[test != ""] ## delete "" in case of error in following operation
return(splitted)
}
splitted_words_origin <- split_punct(a)
splitted_words <- tolower(splitted_words_origin) ## replaced capital letters
uni_words <- unique(splitted_words) ## a vector of unique words
uid <- match(splitted_words, uni_words) ## vector of indicies indicating which element in the unique word vector each element in the bible text corresponds to
tab <- tabulate(uid) ## count up how many times each unique word occurs in the text
freq <- sort(tab, decreasing = T) ## sort the times each word occurs in decreasing order
m <- 1000 ## the number of words that will be used to train the model
threshold <- freq[m] ## search for the threshold number of the m most common words, but may require further adjustment according to the result of next step
b <- uni_words[which(tab >= threshold)] ## select the m most common words to create vector b
mat_word <- match(splitted_words, b) ## a vector giving which element of  vector, b, each element of the full text vector corresponds to
prior <- mat_word[1:(length(mat_word) - 1)] ## the first column, which is the index for common words
following <- mat_word[2:length(mat_word)] ## the second column, which gives the following words
pair_words <- cbind(prior, following) ## a matrix where each row is a pair of common words
pair_words <- pair_words[- which(is.na(rowSums(pair_words))),] ## delete rows having NA
A <- matrix(0, length(b), length(b)) ## a matrix where A[i,j] means the jth word in the common words follows the ith word
for (k in 1:dim(pair_words)[1]) {
i = pair_words[k, 1]
j = pair_words[k, 2]
A[i,j] = A[i,j] + 1
} ## caculate how many times the ith common word is followed by the jth common word
for (k in 1:length(b)) {
A[k, ] <- A[k, ]/sum(A[k, ])
} ## standardize each row of A, so that A[i,j] can be interpreted as probablity that b[j] will follow b[i]
prior_word <- sample(b, size = 1)  ##  starting from a randomly selected entry in vector b
num_words <- 50 ## how many words the model will simulate
sentence <- rep("", num_words) ## a vector to store words in the sentence
sentence[1] <- prior_word
for (i in 2:num_words) {
ipwords <- match(prior_word, b) ## find the position of the word in vector b
pr <- A[ipwords, ] ## the probabilities of each word in b following this word
sentence[i] <- b[sample(length(b), size = 1, prob = pr)] ## select one word according to the probablities
prior_word <- sentence[i] ## update the prior word
}
cat(sentence) ## print out the text
sentence
?gregexpr()
splitted_words_capital <-
splitted_words_origin[unlist(gregexpr("^[A-Z]", splitted_words_origin)) == 1]
splitted_words_capital <- na.omit(splitted_words_capital)
uni_capital_words <- unique(tolower(splitted_words_capital))
uid_capital <- match(tolower(splitted_words_capital), uni_capital_words)
tab_capital <- tabulate(uid_capital)
tab_capital_sum <- tabulate(match(splitted_words, uni_capital_words))
prob_capital <- tab_capital / tab_capital_sum ## Probability of a word being capitalised in the text
firstupper <- function(x) {
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
return(x)
}
for (i in seq_len(length(sentence))) {
if (grep(sentence[i], uni_capital_words) == 0) next
sentence_capital <-
sample(c(sentence[i], firstupper(sentence[i])),size = 1, prob = prob_capital[grep(sentence[i], uni_capital_words)])
}
prob_capital[grep("god", uni_capital_words)]
?unique
unique(splitted_words_capital)
length(unique(splitted_words_capital))
unique(tolower(splitted_words_capital)[1:100])
unique(tolower(splitted_words_capital)[1:1000])
uni_capital_words[grep("god", uni_capital_words)]
unique(tolower(splitted_words_origin[5e5:6e5][unlist(gregexpr("^[A-Z]", splitted_words_origin[5e5:6e5])) == 1]))
uni_capital_words[grep(uni_capital_words[1], uni_capital_words)]
?gregexpr
uni_capital_words[grep(uni_capital_words[1], uni_capital_words)]
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, fixed = T)]
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, fixed = F)]
uni_capital_words[1]
grep(uni_capital_words[1], uni_capital_words, fixed = F)
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, fixed = T)]
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, useBytes = T)]
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, useBytes = F)]
grep(uni_capital_words[1], uni_capital_words, fixed = TRUE)
grep(uni_capital_words[1], uni_capital_words, fixed = T)
grep("uni_capital_words[1]", uni_capital_words, fixed = T)
grep("god", uni_capital_words, fixed = T)
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, useBytes = F)]
gregexpr("god", uni_capital_words, fixed = T)
unlist(gregexpr("god", uni_capital_words, fixed = T))
uni_capital_words[unlist(gregexpr("god", uni_capital_words, fixed = T)) == 1]
unique(tolower(splitted_words_origin[5e5:6e5][unlist(gregexpr("^[A-Z]", splitted_words_origin[5e5:6e5])) == 1]))
gregexpr("^[A-Z]", splitted_words_origin[5e5:6e5])
grep("^[A-Z]", splitted_words_origin[5e5:6e5])
unlist(gregexpr("^[A-Z]", splitted_words_origin[5e5:6e5]))
unique(tolower(splitted_words_origin[5e5:6e5][unlist(gregexpr("^[A-Z]", splitted_words_origin[5e5:6e5])) == 1]))
tolower(splitted_words_origin[5e5:6e5][unlist(gregexpr("^[A-Z]", splitted_words_origin[5e5:6e5])) == 1])
splitted_words_capital <-
splitted_words_origin[grep("^[A-Z]", splitted_words_origin)]
splitted_words_capital
splitted_words_capital <- na.omit(splitted_words_capital)
uni_capital_words <- unique(tolower(splitted_words_capital))
splitted_words_capital
splitted_words_capital <-
splitted_words_origin[grep("^[A-Z]", splitted_words_origin)]
splitted_words_capital <-
splitted_words_origin[grep("^[A-Z]", splitted_words_origin)]##find all words start with capital letter
uni_capital_words <- unique(tolower(splitted_words_capital))
uid_capital <- match(tolower(splitted_words_capital), uni_capital_words)
tab_capital <- tabulate(uid_capital)
tab_capital_sum <- tabulate(match(splitted_words, uni_capital_words))
prob_capital <- tab_capital / tab_capital_sum ## Probability of a word being capitalised in the text
prob_capital
uni_capital_words
firstupper <- function(x) {
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
return(x)
}
for (i in seq_len(length(sentence))) {
if (grep(sentence[i], uni_capital_words) == 0) next
sentence_capital <-
sample(c(sentence[i], firstupper(sentence[i])),size = 1, prob = prob_capital[grep(sentence[i], uni_capital_words)])
}
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, useBytes = F)]
grep("app", astring)
astring = c("apple", "banana", "orange", "apple","apple","apple")
grep("app", astring)
grep("app", astring, fixed = T)
grep("app"?, astring, fixed = T)
grep("app?", astring, fixed = T)
grep("?app", astring, fixed = T)
grep("?app", astring)
grep("app?", astring)
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, useBytes = F)]
prob_capital[uni_capital_words[grep(uni_capital_words[1], uni_capital_words, useBytes = F)]]
uni_capital_words[grep(uni_capital_words[1], uni_capital_words, useBytes = F)]
grep(uni_capital_words[1], uni_capital_words, useBytes = F)
grep(<"app">, astring)
grep("<app>", astring)
grep("<appple>", astring)
grep("<apple>", astring)
grep("<apple>", astring, fixed = T)
grep(<apple>, astring, fixed = T)
?regex
regex(<apple>, astring, fixed = T)
regexpr(<apple>, astring, fixed = T)
regexpr("<apple>", astring, fixed = T)
unlist(regexpr("<apple>", astring, fixed = T))
unlist(regexpr("apple", astring, fixed = T))
unlist(regexpr("apple", astring, fixed = T)[1])
unlist(regexpr("apple", astring, fixed = T))[1]
unlist(regexpr("apple", astring, fixed = T))
unlist(regexpr("apple", astring, fixed = T))[[1]]
unlist(regexpr("apple", astring, fixed = T)[[1]])
(regexpr("apple", astring, fixed = T)[[1]])
regexpr("apple", astring, fixed = T)[1]
regexpr("apple", astring, fixed = T)
regexpc("apple", astring, fixed = T)
regexec("apple", astring, fixed = T)
regexpr("apple", astring, fixed = T)
astring[regexpr("apple", astring, fixed = T)]
astring[regexpr("apple", astring, fixed = T)==1]
astring[regexpr("app", astring, fixed = T)==1]
astring[regexpr("<app>", astring, fixed = T)==1]
astring[regexpr("<apple>", astring, fixed = T)==1]
astring[regexpr("<apple>", astring)==1]
astring[regexpr("<apple", astring)==1]
astring[grep("<apple", astring)==1]
astring[grep("apple", astring)==1]
grep("apple", astring)==1
grep("apple", astring)
splitted_words_capital
grep(["apple"], astring)
grep("[apple]", astring)
?pattern
>??pattern
??pattern
grep(as.character("app"), astring)
cat(sentence) ## print out the text
uid_capital
uni_capital_words
tab_capital
prob_capital[tab_capital[sentence[1] == uni_capital_words]]
sentence[1]
prob_capital[grep("silver", uni_capital_words)]
grep("silver", uni_capital_words)
tab_capital[sentence[1] == uni_capital_words]
tab_capital
uni_capital_words
uid_capital
tab_capital
which(sentence[1] == uni_capital_words)
uni_capital_words
prob_capital[grep("silver", uni_capital_words)]
prob_capital[which(sentence[1] == uni_capital_words)]
firstupper <- function(x) {
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
return(x)
}
for (i in seq_len(length(sentence))) {
if (grep(sentence[i], uni_capital_words) == 0) next
sentence_capital <-
sample(c(sentence[i], firstupper(sentence[i])),size = 1, prob = prob_capital[which(sentence[i] == uni_capital_words)])
}
sentence
prob_capital[which(sentence[2] == uni_capital_words)]
for (i in seq_len(length(sentence))) {
if (which(sentence[i] == uni_capital_words) == 0) next
sentence_capital <-
sample(c(sentence[i], firstupper(sentence[i])),size = 1, prob = prob_capital[which(sentence[i] == uni_capital_words)])
}
sentence_capital <- rep("", length(sentence))
for (i in seq_len(length(sentence))) {
if (which(sentence[i] == uni_capital_words) == 0) next
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])),size = 1, prob = prob_capital[which(sentence[i] == uni_capital_words)])
}
sentence_capital
for (i in seq_len(length(sentence))) {
if (which(sentence[i] == uni_capital_words) == 0) next
prob_i = prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])),size = 1, prob = c(1-prob_i,prob_i))
}
which(sentence[i] == uni_capital_words)
which(sentence[1] == uni_capital_words)
which(sentence[1] == uni_capital_words) == 0
splitted_words_capital <-
splitted_words_origin[grep("^[A-Z]", splitted_words_origin)]##find all words start with capital letter
uni_capital_words <- unique(tolower(splitted_words_capital))
uid_capital <- match(tolower(splitted_words_capital), uni_capital_words)
tab_capital <- tabulate(uid_capital)
tab_capital_sum <- tabulate(match(splitted_words, uni_capital_words))
prob_capital <- tab_capital / tab_capital_sum ## Probability of a word being capitalised in the text
firstupper <- function(x) {
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
return(x)
}
sentence_capital <- rep("", length(sentence))
for (i in seq_len(length(sentence))) {
if (which(sentence[1] == uni_capital_words) == 0) next
prob_i = prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])),size = 1, prob = c(1-prob_i,prob_i))
}
for (i in seq_len(length(sentence))) {
if (which(sentence[1] == uni_capital_words) == 0) next
prob_i = prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), prob = c(1-prob_i,prob_i))
}
sample(c("apple", "banana"), c(0.7,03))
sample(c("apple", "banana"), c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,03), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,0.3), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,0.3), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,0.3), size = 1)
sample(c("apple", "banana"),prob =  c(0.7,0.3), size = 1)
for (i in seq_len(length(sentence))) {
if (which(sentence[1] == uni_capital_words) == 0) next
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c(1-prob_i,prob_i))
}
for (i in seq_len(length(sentence))) {
if (which(sentence[1] == uni_capital_words) == 0) next
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
prob_example <- prob_capital[which(sentence[2] == uni_capital_words)]
sample(c(sentence[2], firstupper(sentence[2])), size = 1, prob = c((1-prob_example),prob_example))
prob_example
sentence[2]
which(sentence[2] == uni_capital_words)
for (i in seq_len(length(sentence))) {
if (which(sentence[1] == uni_capital_words) == integer(0)) next
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
for (i in seq_len(length(sentence))) {
if (which(sentence[1] == uni_capital_words) == integer(0)) next
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
for (i in seq_len(length(sentence))) {
if (which(sentence[i] == uni_capital_words) == integer(0)) next
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
sample(c("apple", "banana"),prob =  c(0.7,0.3), size = 1)
sample(c(sentence[2], firstupper(sentence[2])), size = 1, prob = c((1-prob_example),prob_example))
c(sentence[2], firstupper(sentence[2]))
sample(c(sentence[3], firstupper(sentence[3])), size = 1, prob = c((1-prob_example),prob_example))
c(sentence[3], firstupper(sentence[3]))
prior_word <- sample(b, size = 1)  ##  starting from a randomly selected entry in vector b
num_words <- 50 ## how many words the model will simulate
sentence <- rep("", num_words) ## a vector to store words in the sentence
sentence[1] <- prior_word
for (i in 2:num_words) {
ipwords <- match(prior_word, b) ## find the position of the word in vector b
pr <- A[ipwords, ] ## the probabilities of each word in b following this word
sentence[i] <- b[sample(length(b), size = 1, prob = pr)] ## select one word according to the probablities
prior_word <- sentence[i] ## update the prior word
}
cat(sentence) ## print out the text
prob_example <- prob_capital[which(sentence[2] == uni_capital_words)]
sample(c(sentence[3], firstupper(sentence[3])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[3], firstupper(sentence[3])), size = 1, prob = c((1-prob_example),prob_example))
c(sentence[3], firstupper(sentence[3]))
prob_example <- prob_capital[which(sentence[2] == uni_capital_words)]
sample(c(sentence[3], firstupper(sentence[3])), size = 1, prob = c((1-prob_example),prob_example))
prob_example <- prob_capital[which(sentence[3] == uni_capital_words)]
sample(c(sentence[3], firstupper(sentence[3])), size = 1, prob = c((1-prob_example),prob_example))
prob_example
sentence[3]
prob_example <- prob_capital[which(sentence[4] == uni_capital_words)]
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
c(sentence[4], firstupper(sentence[4]))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
prob_example
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
sample(c(sentence[4], firstupper(sentence[4])), size = 1, prob = c((1-prob_example),prob_example))
for (i in seq_len(length(sentence))) {
if (which(sentence[i] == uni_capital_words) != 0) {
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
}
for (i in seq_len(length(sentence))) {
if (prob_capital[which(sentence[i] == uni_capital_words)] != 0) {
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
}
which(sentence[4] == uni_capital_words)
class(which(sentence[4] == uni_capital_words))
for (i in seq_len(length(sentence))) {
if (prob_capital[which(sentence[i] == uni_capital_words)] != integer(0)) {
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
}
sentence_capital <- rep("", length(sentence))
for (i in seq_len(length(sentence))) {
if (prob_capital[which(sentence[i] == uni_capital_words)] != integer(0)) {
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
}
prob_capital[which(sentence[i] == uni_capital_words)] != integer(0)
prob_capital[which(sentence[3] == uni_capital_words)] == 0
length(prob_capital[which(sentence[3] == uni_capital_words)] == 0)
length(prob_capital[which(sentence[1] == uni_capital_words)] == 0)
prob_capital[which(sentence[1] == uni_capital_words)]
which(sentence[1] == uni_capital_words)
length(which(sentence[1] == uni_capital_words) == 0)
length(which(sentence[3] == uni_capital_words) == 0)
which(sentence[3] == uni_capital_words) == 0
which(sentence[3] == uni_capital_words)
for (i in seq_len(length(sentence))) {
for (i in seq_len(length(sentence))) {
if (length(which(sentence[i] == uni_capital_words) == 0)) next
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
length(which(sentence[i] == uni_capital_words) == 0)
length(which(sentence[1] == uni_capital_words) == 0)
length(which(sentence[3] == uni_capital_words) == 0)
length(which(sentence[2] == uni_capital_words) == 0)
for (i in seq_len(length(sentence))) {
if (length(which(sentence[i] == uni_capital_words) == 0)) {
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
}
sentence_capital
cat(sentence_capital)
firstupper <- function(x) {
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
return(x)
}
sentence_capital <- sentence
for (i in seq_len(length(sentence))) {
if (length(which(sentence[i] == uni_capital_words) == 0)) {
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
}
cat(sentence_capital)
cat(sentence)
setwd()
a <- scan("1581-0.txt", what = "character", skip = 156)
n <- length(a)
a <- a[- ((n - 2909):n)] ## strip license
split_punct <- function(test){
punc <- c(",", ".", ";", "!", ":","?")
for (i in 1:length(punc)) {
p <- punc[i]
ipunc <- grep(p, test, fixed = T) ## search for words containing this mark
npunc <- length(ipunc) ## number of words containing this punctuation
if (npunc == 0) next ## if all words don't contain this punctuation, skip to next loop
spunc <- rep("", length(test) + npunc) ## create a new vectore to store the splited words
sii <- ipunc + 1:npunc ## vector to store the position of this punctuations
spunc[sii] <- p ## insert the punctuations
spunc[sii-1] <- gsub(p, "", test[ipunc], fixed = TRUE) ## insert words the punctuations attacthed to
spunc[-c(sii, sii-1)] <- test[-ipunc] ## insert other words
test <- spunc ## update words vector
}
splitted <- test[test != ""] ## delete "" in case of error in following operation
return(splitted)
}
splitted_words_origin <- split_punct(a)
splitted_words <- tolower(splitted_words_origin) ## replaced capital letters
uni_words <- unique(splitted_words) ## a vector of unique words
uid <- match(splitted_words, uni_words) ## vector of indicies indicating which element in the unique word vector each element in the bible text corresponds to
tab <- tabulate(uid) ## count up how many times each unique word occurs in the text
freq <- sort(tab, decreasing = T) ## sort the times each word occurs in decreasing order
m <- 1000 ## the number of words that will be used to train the model
threshold <- freq[m] ## search for the threshold number of the m most common words, but may require further adjustment according to the result of next step
b <- uni_words[which(tab >= threshold)] ## select the m most common words to create vector b
mat_word <- match(splitted_words, b) ## a vector giving which element of  vector, b, each element of the full text vector corresponds to
prior <- mat_word[1:(length(mat_word) - 1)] ## the first column, which is the index for common words
following <- mat_word[2:length(mat_word)] ## the second column, which gives the following words
pair_words <- cbind(prior, following) ## a matrix where each row is a pair of common words
pair_words <- pair_words[- which(is.na(rowSums(pair_words))),] ## delete rows having NA
A <- matrix(0, length(b), length(b)) ## a matrix where A[i,j] means the jth word in the common words follows the ith word
for (k in 1:dim(pair_words)[1]) {
i = pair_words[k, 1]
j = pair_words[k, 2]
A[i,j] = A[i,j] + 1
} ## caculate how many times the ith common word is followed by the jth common word
for (k in 1:length(b)) {
A[k, ] <- A[k, ]/sum(A[k, ])
} ## standardize each row of A, so that A[i,j] can be interpreted as probablity that b[j] will follow b[i]
prior_word <- sample(b, size = 1)  ##  starting from a randomly selected entry in vector b
num_words <- 50 ## how many words the model will simulate
sentence <- rep("", num_words) ## a vector to store words in the sentence
sentence[1] <- prior_word
for (i in 2:num_words) {
ipwords <- match(prior_word, b) ## find the position of the word in vector b
pr <- A[ipwords, ] ## the probabilities of each word in b following this word
sentence[i] <- b[sample(length(b), size = 1, prob = pr)] ## select one word according to the probablities
prior_word <- sentence[i] ## update the prior word
}
cat(sentence) ## print out the text without capital letters
##Uppercase conversion
splitted_words_capital <-
splitted_words_origin[grep("^[A-Z]", splitted_words_origin)]##find all words start with capital letter
uni_capital_words <- unique(tolower(splitted_words_capital))
uid_capital <- match(tolower(splitted_words_capital), uni_capital_words)
tab_capital <- tabulate(uid_capital)
tab_capital_sum <- tabulate(match(splitted_words, uni_capital_words))
prob_capital <- tab_capital / tab_capital_sum ## Probability of a word being capitalised in the text
firstupper <- function(x) {
substr(x, 1, 1) <- toupper(substr(x, 1, 1))
return(x)
} ##set a function to capitalize the first letter
sentence_capital <- sentence
for (i in seq_len(length(sentence))) {
if (length(which(sentence[i] == uni_capital_words) == 0)) {
prob_i <- prob_capital[which(sentence[i] == uni_capital_words)]
sentence_capital[i] <-
sample(c(sentence[i], firstupper(sentence[i])), size = 1, prob = c((1-prob_i),prob_i))
}
}
cat(sentence_capital)
cat(sentence)
